{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "16019e7e",
      "metadata": {
        "id": "16019e7e"
      },
      "source": [
        "# Voice Recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "IdOxBRVj-2e1"
      },
      "id": "IdOxBRVj-2e1"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets torchaudio torchcodec soundfile\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Getting Kaggle credentials and setting in environment\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYVRxB0h-wNg",
        "outputId": "5867df9b-e9ac-4d08-846e-15dbac0d8d87"
      },
      "id": "uYVRxB0h-wNg",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.1 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "7DiO22vS_fVu"
      },
      "id": "7DiO22vS_fVu"
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "import os\n",
        "\n",
        "# Creamos la carpeta para los datos\n",
        "os.makedirs('./temp_data', exist_ok=True)\n",
        "\n",
        "# Descargamos la versión 0.02\n",
        "dataset_train = SPEECHCOMMANDS(root='./temp_data', url='speech_commands_v0.02', download=True, subset='training')\n",
        "\n",
        "print(f\"Dataset descargado. Número de muestras: {len(dataset_train)}\")\n",
        "\n",
        "# Ejemplo de cómo acceder a un dato: waveform, sample_rate, label, speaker_id, utterance_number\n",
        "waveform, sample_rate, label, *_ = dataset_train[0]\n",
        "print(f\"Etiqueta: {label}, Forma de onda: {waveform.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWLzsnqK_iX0",
        "outputId": "23936121-3982-4627-c38c-f5d41ad086c0"
      },
      "id": "RWLzsnqK_iX0",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset descargado. Número de muestras: 84843\n",
            "Etiqueta: backward, Forma de onda: torch.Size([1, 16000])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}