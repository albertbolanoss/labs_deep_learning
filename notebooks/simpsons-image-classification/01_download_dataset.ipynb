{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Simpsons Image Classification."
      ],
      "metadata": {
        "id": "3qIQxv5KPi_H"
      },
      "id": "3qIQxv5KPi_H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Download Dataset."
      ],
      "metadata": {
        "id": "i3szLDo3S5Ox"
      },
      "id": "i3szLDo3S5Ox"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "kaggle_dataset = \"alexattia/the-simpsons-characters-dataset\"\n",
        "target_unzip_dataset = \"/content/simpsons_data\"\n",
        "\n",
        "# Getting Kaggle credentials and setting in environment\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# Download and unzip dataset from Kaggle\n",
        "!kaggle datasets download -d {kaggle_dataset}\n",
        "!unzip -q the-simpsons-characters-dataset.zip -d {target_unzip_dataset}\n",
        "\n",
        "print(f\"Downloaded {kaggle_dataset} in {target_unzip_dataset}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gYgY2cKQEZq",
        "outputId": "d9fd0e97-b031-4d1a-a313-b71d6a52914b"
      },
      "id": "-gYgY2cKQEZq",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/alexattia/the-simpsons-characters-dataset\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "the-simpsons-characters-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace /content/simpsons_data/annotation.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/simpsons_data/characters_illustration.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/simpsons_data/kaggle_simpson_testset/kaggle_simpson_testset/abraham_grampa_simpson_0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/simpsons_data/kaggle_simpson_testset/kaggle_simpson_testset/abraham_grampa_simpson_1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "A\n",
            "A\n",
            "y\n",
            "y\n",
            "A\n",
            "Downloaded alexattia/the-simpsons-characters-dataset in /content/simpsons_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Prepare Dataset."
      ],
      "metadata": {
        "id": "_H0lwmIxTTHq"
      },
      "id": "_H0lwmIxTTHq"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sets the source dataset directory and the image size to be resize\n",
        "# Shuffle is simply \"shuffling\" or mixing up the order of your data.\n",
        "DATA_DIR = '/content/simpsons_data/simpsons_dataset'\n",
        "IMG_WIDTH = 64\n",
        "IMG_HEIGHT = 64\n",
        "\n",
        "def load_simpsons_dataset_with_labels(directory, img_width, img_height):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = sorted(os.listdir(directory))\n",
        "    class_map = {name: i for i, name in enumerate(class_names)}\n",
        "\n",
        "    # Browse folders\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        if not os.path.isdir(class_dir):\n",
        "            continue\n",
        "\n",
        "        class_idx = class_map[class_name]\n",
        "\n",
        "        # Read images from each folder\n",
        "        for img_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_name)\n",
        "            try:\n",
        "                # Read image with OpenCV\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    # Convert BGR (OpenCV) to RGB\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    # Resize (CNN needs fixed size)\n",
        "                    img = cv2.resize(img, (img_width, img_height))\n",
        "\n",
        "                    images.append(img)\n",
        "                    labels.append(class_idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Error cargando {img_path}: {e}\")\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X = np.array(images)\n",
        "    y = np.array(labels)\n",
        "\n",
        "    # Mix data (Shuffle)\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "    X = X[indices]\n",
        "    y = y[indices]\n",
        "\n",
        "    return X, y, class_names\n",
        "\n",
        "# Load the full dataset with labels\n",
        "print(\"Loading datasets with labels may take a while\")\n",
        "\n",
        "X_full, y_full, class_names = load_simpsons_dataset_with_labels(DATA_DIR, IMG_WIDTH, IMG_HEIGHT)\n",
        "\n",
        "print(f\"# of samples: {len(X_full)}\")\n",
        "print(f\"# of clases: {len(class_names)}: {class_names}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luqIY__qTWi3",
        "outputId": "526c61fc-6c62-46d1-847d-38197ece1f63"
      },
      "id": "luqIY__qTWi3",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets with labels may take a while\n",
            "Detected 43 classes.\n",
            "# of samples: 20933\n",
            "# of clases: 43: ['abraham_grampa_simpson', 'agnes_skinner', 'apu_nahasapeemapetilon', 'barney_gumble', 'bart_simpson', 'carl_carlson', 'charles_montgomery_burns', 'chief_wiggum', 'cletus_spuckler', 'comic_book_guy', 'disco_stu', 'edna_krabappel', 'fat_tony', 'gil', 'groundskeeper_willie', 'homer_simpson', 'kent_brockman', 'krusty_the_clown', 'lenny_leonard', 'lionel_hutz', 'lisa_simpson', 'maggie_simpson', 'marge_simpson', 'martin_prince', 'mayor_quimby', 'milhouse_van_houten', 'miss_hoover', 'moe_szyslak', 'ned_flanders', 'nelson_muntz', 'otto_mann', 'patty_bouvier', 'principal_skinner', 'professor_john_frink', 'rainier_wolfcastle', 'ralph_wiggum', 'selma_bouvier', 'sideshow_bob', 'sideshow_mel', 'simpsons_dataset', 'snake_jailbird', 'troy_mcclure', 'waylon_smithers']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}