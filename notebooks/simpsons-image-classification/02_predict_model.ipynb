{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c7d30b",
   "metadata": {},
   "source": [
    "## Predict Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794c50e",
   "metadata": {},
   "source": [
    "### 0. Initial Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a570b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "\n",
    "# The Google Drive Folder ID to read / write files\n",
    "GOOGLE_DRIVE_FOLDER_ID = \"1GZ0NBMKvCcNAvPdW50j6OwcSasaoK8A1\"\n",
    "\n",
    "# The train dataset\n",
    "VAL_DATASET = \"simpsons_val_data.npz\"\n",
    "\n",
    "# The test dataset\n",
    "TEST_DATASET = \"simpsons_test_data.npz\"\n",
    "\n",
    "# Request permissions to access (read/write) the Google Drive Folder ID\n",
    "auth.authenticate_user()\n",
    "drive_service = build('drive', 'v3')\n",
    "\n",
    "print(f\"Successful initialization: Dataset: {KAGGLE_DATASET} - Google Drive Id: {GOOGLE_DRIVE_FOLDER_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9361a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "from tensorflow.keras.models import load_model as keras_load_model\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
    "\n",
    "\n",
    "def load_dataset(folder_id, filename):\n",
    "    query = f\"name = '{filename}' and '{folder_id}' in parents and trashed = false\"\n",
    "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    if not items:\n",
    "        print(f\"No found the file '{filename}' in the folder '{folder_id}'.\")\n",
    "        return None, None, None\n",
    "\n",
    "    file_id = items[0]['id']\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    fh = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "    done = False\n",
    "    while done is False:\n",
    "        status, done = downloader.next_chunk()\n",
    "        print(f\"Download progress: {int(status.progress() * 100)}%\")\n",
    "\n",
    "    # Load NumPy data from the memory buffer\n",
    "    fh.seek(0)\n",
    "    data = np.load(fh, allow_pickle=True)\n",
    "\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    labels = data['labels']\n",
    "\n",
    "    print(\"Data successfully loaded.\")\n",
    "    return X, y, labels\n",
    "\n",
    "\n",
    "def display_image(x_data, y_data, index, class_names=None):\n",
    "    \"\"\"\n",
    "    Displays an image from the dataset with its numeric and text label.\n",
    "    \"\"\"\n",
    "    img = x_data[index]\n",
    "    label_raw = y_data[index]\n",
    "\n",
    "    # 1. Handle One-Hot or Integer labels\n",
    "    if hasattr(label_raw, '__len__') and len(label_raw) > 1:\n",
    "        label_id = np.argmax(label_raw)\n",
    "    else:\n",
    "        label_id = int(np.array(label_raw).item())\n",
    "\n",
    "    # 2. Setup Plot\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    # If images were normalized (0-1 float), imshow handles it.\n",
    "    # If they are 0-255 int, we ensure the type is uint8.\n",
    "    if img.max() > 1.0 and img.dtype != np.uint8:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # 3. Create Title (Numeric ID + Name)\n",
    "    title = f\"Index: {index} | Label ID: {label_id}\"\n",
    "\n",
    "    if class_names is not None:\n",
    "        try:\n",
    "            character_name = class_names[label_id]\n",
    "            title += f\"\\nCharacter: {character_name.replace('_', ' ').title()}\"\n",
    "        except IndexError:\n",
    "            title += \"\\n(Name not found in class_names)\"\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_colab_capabilities():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "\n",
    "  ram_gb = psutil.virtual_memory().total / 1e9\n",
    "\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "  else:\n",
    "    print(gpu_info)\n",
    "\n",
    "  print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "  if ram_gb < 20:\n",
    "    print('Not using a high-RAM runtime')\n",
    "  else:\n",
    "    print('You are using a high-RAM runtime!')\n",
    "\n",
    "\n",
    "def load_model_from_drive(folder_id, filename):\n",
    "    \"\"\"\n",
    "    Searches for a model file in a specific Google Drive folder,\n",
    "    downloads it locally, and loads it as a Keras model.\n",
    "    \"\"\"\n",
    "    # 1. Search for the file in the specified Drive folder\n",
    "    query = f\"name = '{filename}' and '{folder_id}' in parents and trashed = false\"\n",
    "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    if not items:\n",
    "        print(f\"Error: File '{filename}' not found in the specified Drive folder.\")\n",
    "        return None\n",
    "\n",
    "    file_id = items[0]['id']\n",
    "    local_path = filename  # Local path in the Colab environment\n",
    "\n",
    "    # 2. Download the file from Google Drive\n",
    "    print(f\"Downloading model from Drive (ID: {file_id})...\")\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "\n",
    "    with io.FileIO(local_path, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            if status:\n",
    "                print(f\"   Download Progress: {int(status.progress() * 100)}%\")\n",
    "\n",
    "    # 3. Reconstruct the Keras model object\n",
    "    try:\n",
    "        # We use 'keras_load_model' (the alias) to ensure we don't call this function recursively\n",
    "        model = keras_load_model(local_path)\n",
    "        print(f\"Model '{filename}' loaded successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model with Keras: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_dataset_from_drive(folder_id, filename):\n",
    "    query = f\"name = '{filename}' and '{folder_id}' in parents and trashed = false\"\n",
    "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    if not items:\n",
    "        print(f\"No found '{filename}' in Drive.\")\n",
    "        return None, None, None\n",
    "\n",
    "    file_id = items[0]['id']\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    fh = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        status, done = downloader.next_chunk()\n",
    "        print(f\"Download dataset: {int(status.progress() * 100)}%\")\n",
    "\n",
    "    fh.seek(0)\n",
    "    data = np.load(fh, allow_pickle=True)\n",
    "    print(\"Dataset sucessful loaded.\")\n",
    "    return data['X'], data['y'], data['labels']\n",
    "\n",
    "\n",
    "def predict_and_visualize(model, image_array, real_label_name=None, class_names=None):\n",
    "    \"\"\"\n",
    "    Predice y visualiza la imagen al estilo del screenshot: \n",
    "    Imagen a la izquierda y Top 10 de confianza a la derecha.\n",
    "    \"\"\"\n",
    "    # 1. Preparar imagen y Predecir\n",
    "    img_batch = np.expand_dims(image_array, axis=0)\n",
    "    predictions = model.predict(img_batch, verbose=0)[0]\n",
    "    \n",
    "    # Obtener el Top 10\n",
    "    top_indices = predictions.argsort()[-10:][::-1]\n",
    "    top_labels = [class_names[i] for i in top_indices]\n",
    "    top_probs = [predictions[i] for i in top_indices]\n",
    "    \n",
    "    predicted_label = class_names[np.argmax(predictions)]\n",
    "\n",
    "    # 2. Crear la figura\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # --- LADO IZQUIERDO: IMAGEN ---\n",
    "    ax1.imshow(image_array)\n",
    "    \n",
    "    # Determinar color del título (Verde si acertó, Rojo si no)\n",
    "    is_correct = real_label_name == predicted_label\n",
    "    color_title = 'green' if is_correct else 'red'\n",
    "    \n",
    "    title_text = f\"Predicho: {predicted_label}\"\n",
    "    if real_label_name:\n",
    "        title_text = f\"Real: {real_label_name}\\n{title_text}\"\n",
    "    \n",
    "    ax1.set_title(title_text, color=color_title, fontsize=15, fontweight='bold', loc='center')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # --- LADO DERECHO: GRÁFICO DE BARRAS ---\n",
    "    # Solo pintamos de verde la barra con mayor probabilidad\n",
    "    bar_colors = ['green'] + ['#424242'] * 9 \n",
    "    \n",
    "    ax2.barh(top_labels, top_probs, color=bar_colors)\n",
    "    ax2.invert_yaxis()  # Para que el más alto esté arriba\n",
    "    ax2.set_title(\"Top 10 Predicciones del Modelo\", fontsize=12)\n",
    "    ax2.set_xlabel(\"Confianza (0 a 1)\")\n",
    "    ax2.set_xlim(0, 1.05)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- DETALLE EN TEXTO (Consola) ---\n",
    "    print(\"=\"*55)\n",
    "    print(\"DETALLE DE PROBABILIDADES (Top 10)\")\n",
    "    print(\"=\"*55)\n",
    "    for i in top_indices:\n",
    "        real_marker = \"<< REAL\" if (real_label_name and class_names[i] == real_label_name) else \"\"\n",
    "        print(f\"{class_names[i]:<25}: {predictions[i]*100:>6.2f}% {real_marker}\")\n",
    "    print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd6c53",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model_from_drive(GOOGLE_DRIVE_FOLDER_ID, FINAL_MODEL_FILENAME)\n",
    "X_test, y_test, classNames = load_dataset(GOOGLE_DRIVE_FOLDER_ID, TEST_DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf36d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Verificamos que los datos existan\n",
    "if 'X_test' in locals() and X_test is not None:\n",
    "    # Seleccionar un índice al azar\n",
    "    idx = random.randint(0, len(X_test) - 1)\n",
    "    \n",
    "    # Obtener imagen y etiqueta\n",
    "    sample_img = X_test[idx]\n",
    "    \n",
    "    # Obtener el nombre real (y_test suele ser One-Hot por el código que compartiste)\n",
    "    label_id = np.argmax(y_test[idx]) if y_test[idx].ndim > 0 else int(y_test[idx])\n",
    "    real_name = class_names[label_id]\n",
    "\n",
    "    print(f\"Analizando imagen del set de TEST índice: {idx}\")\n",
    "    predict_and_visualize(model, sample_img, real_label_name=real_name, class_names=class_names)\n",
    "else:\n",
    "    print(\"Error: El dataset X_test no está cargado. Ejecuta primero la carga de datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb5c53",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    # 1. Cargar imagen\n",
    "    raw_img = Image.open(io.BytesIO(uploaded[filename]))\n",
    "    \n",
    "    # 2. FEATURE ENGINEERING\n",
    "    # Convertir a RGB (por si es PNG con transparencia o escala de grises)\n",
    "    img_rgb = raw_img.convert('RGB')\n",
    "    \n",
    "    # Redimensionar a 64x64\n",
    "    img_resized = img_rgb.resize((64, 64))\n",
    "    \n",
    "    # Convertir a array de numpy\n",
    "    img_array = np.array(img_resized)\n",
    "    \n",
    "    # Normalizar (Pasar de 0-255 a 0-1)\n",
    "    img_normalized = img_array.astype('float32') / 255.0\n",
    "    \n",
    "    # 3. Predicción\n",
    "    print(f\"\\nProcesando archivo: {filename}\")\n",
    "    predict_and_visualize(model, img_normalized, real_label_name=None, class_names=class_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
