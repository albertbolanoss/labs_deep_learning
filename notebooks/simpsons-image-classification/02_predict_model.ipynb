{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c7d30b",
   "metadata": {},
   "source": [
    "## Predict Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794c50e",
   "metadata": {},
   "source": [
    "### 0. Initial Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a570b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "\n",
    "# The Google Drive Folder ID to read / write files\n",
    "GOOGLE_DRIVE_FOLDER_ID = \"1GZ0NBMKvCcNAvPdW50j6OwcSasaoK8A1\"\n",
    "\n",
    "# The train dataset\n",
    "VAL_DATASET = \"simpsons_val_data.npz\"\n",
    "\n",
    "# The test dataset\n",
    "TEST_DATASET = \"simpsons_test_data.npz\"\n",
    "\n",
    "# Request permissions to access (read/write) the Google Drive Folder ID\n",
    "auth.authenticate_user()\n",
    "drive_service = build('drive', 'v3')\n",
    "\n",
    "print(f\"Successful initialization: Dataset: {KAGGLE_DATASET} - Google Drive Id: {GOOGLE_DRIVE_FOLDER_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9361a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "from tensorflow.keras.models import load_model as keras_load_model\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
    "\n",
    "\n",
    "def load_dataset(folder_id, filename):\n",
    "    query = f\"name = '{filename}' and '{folder_id}' in parents and trashed = false\"\n",
    "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    if not items:\n",
    "        print(f\"No found the file '{filename}' in the folder '{folder_id}'.\")\n",
    "        return None, None, None\n",
    "\n",
    "    file_id = items[0]['id']\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    fh = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "    done = False\n",
    "    while done is False:\n",
    "        status, done = downloader.next_chunk()\n",
    "        print(f\"Download progress: {int(status.progress() * 100)}%\")\n",
    "\n",
    "    # Load NumPy data from the memory buffer\n",
    "    fh.seek(0)\n",
    "    data = np.load(fh, allow_pickle=True)\n",
    "\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    labels = data['labels']\n",
    "\n",
    "    print(\"Data successfully loaded.\")\n",
    "    return X, y, labels\n",
    "\n",
    "\n",
    "def display_image(x_data, y_data, index, class_names=None):\n",
    "    \"\"\"\n",
    "    Displays an image from the dataset with its numeric and text label.\n",
    "    \"\"\"\n",
    "    img = x_data[index]\n",
    "    label_raw = y_data[index]\n",
    "\n",
    "    # 1. Handle One-Hot or Integer labels\n",
    "    if hasattr(label_raw, '__len__') and len(label_raw) > 1:\n",
    "        label_id = np.argmax(label_raw)\n",
    "    else:\n",
    "        label_id = int(np.array(label_raw).item())\n",
    "\n",
    "    # 2. Setup Plot\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    # If images were normalized (0-1 float), imshow handles it.\n",
    "    # If they are 0-255 int, we ensure the type is uint8.\n",
    "    if img.max() > 1.0 and img.dtype != np.uint8:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # 3. Create Title (Numeric ID + Name)\n",
    "    title = f\"Index: {index} | Label ID: {label_id}\"\n",
    "\n",
    "    if class_names is not None:\n",
    "        try:\n",
    "            character_name = class_names[label_id]\n",
    "            title += f\"\\nCharacter: {character_name.replace('_', ' ').title()}\"\n",
    "        except IndexError:\n",
    "            title += \"\\n(Name not found in class_names)\"\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_colab_capabilities():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "\n",
    "  ram_gb = psutil.virtual_memory().total / 1e9\n",
    "\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "  else:\n",
    "    print(gpu_info)\n",
    "\n",
    "  print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "  if ram_gb < 20:\n",
    "    print('Not using a high-RAM runtime')\n",
    "  else:\n",
    "    print('You are using a high-RAM runtime!')\n",
    "\n",
    "\n",
    "def load_model_from_drive(folder_id, filename):\n",
    "    \"\"\"\n",
    "    Searches for a model file in a specific Google Drive folder,\n",
    "    downloads it locally, and loads it as a Keras model.\n",
    "    \"\"\"\n",
    "    # 1. Search for the file in the specified Drive folder\n",
    "    query = f\"name = '{filename}' and '{folder_id}' in parents and trashed = false\"\n",
    "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    if not items:\n",
    "        print(f\"Error: File '{filename}' not found in the specified Drive folder.\")\n",
    "        return None\n",
    "\n",
    "    file_id = items[0]['id']\n",
    "    local_path = filename  # Local path in the Colab environment\n",
    "\n",
    "    # 2. Download the file from Google Drive\n",
    "    print(f\"Downloading model from Drive (ID: {file_id})...\")\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "\n",
    "    with io.FileIO(local_path, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            if status:\n",
    "                print(f\"   Download Progress: {int(status.progress() * 100)}%\")\n",
    "\n",
    "    # 3. Reconstruct the Keras model object\n",
    "    try:\n",
    "        # We use 'keras_load_model' (the alias) to ensure we don't call this function recursively\n",
    "        model = keras_load_model(local_path)\n",
    "        print(f\"Model '{filename}' loaded successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model with Keras: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_dataset_from_drive(folder_id, filename):\n",
    "    query = f\"name = '{filename}' and '{folder_id}' in parents and trashed = false\"\n",
    "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    if not items:\n",
    "        print(f\"No found '{filename}' in Drive.\")\n",
    "        return None, None, None\n",
    "\n",
    "    file_id = items[0]['id']\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    fh = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        status, done = downloader.next_chunk()\n",
    "        print(f\"Download dataset: {int(status.progress() * 100)}%\")\n",
    "\n",
    "    fh.seek(0)\n",
    "    data = np.load(fh, allow_pickle=True)\n",
    "    print(\"Dataset sucessful loaded.\")\n",
    "    return data['X'], data['y'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd6c53",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model_from_drive(GOOGLE_DRIVE_FOLDER_ID, FINAL_MODEL_FILENAME)\n",
    "X_test, y_test, classNames = load_dataset(GOOGLE_DRIVE_FOLDER_ID, TEST_DATASET)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
